{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":102672,"databundleVersionId":12375409,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nimport copy\n\n# Paths\nBASE_DIR = \"/kaggle/input/soil-classification/soil_classification-2025\"\nTRAIN_DIR = os.path.join(BASE_DIR, \"train\")\nTEST_DIR = os.path.join(BASE_DIR, \"test\")\nLABELS_CSV = os.path.join(BASE_DIR, \"train_labels.csv\")\nTEST_IDS_CSV = os.path.join(BASE_DIR, \"test_ids.csv\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:46:17.615111Z","iopub.execute_input":"2025-05-25T08:46:17.615351Z","iopub.status.idle":"2025-05-25T08:46:27.610003Z","shell.execute_reply.started":"2025-05-25T08:46:17.615327Z","shell.execute_reply":"2025-05-25T08:46:27.609352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(LABELS_CSV)\nlabel_encoder = LabelEncoder()\ntrain_df['label'] = label_encoder.fit_transform(train_df['soil_type'])\nnum_classes = len(label_encoder.classes_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:46:51.818108Z","iopub.execute_input":"2025-05-25T08:46:51.818394Z","iopub.status.idle":"2025-05-25T08:46:51.829569Z","shell.execute_reply.started":"2025-05-25T08:46:51.818363Z","shell.execute_reply":"2025-05-25T08:46:51.828851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SoilDataset(Dataset):\n    def __init__(self, df, image_dir, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_id = self.df.loc[idx, 'image_id']\n        img_path = os.path.join(self.image_dir, img_id)\n        image = Image.open(img_path).convert(\"RGB\")\n        label = self.df.loc[idx, 'label']\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:47:18.319324Z","iopub.execute_input":"2025-05-25T08:47:18.319602Z","iopub.status.idle":"2025-05-25T08:47:18.326423Z","shell.execute_reply.started":"2025-05-25T08:47:18.319581Z","shell.execute_reply":"2025-05-25T08:47:18.325666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\n\nfold_models = []\ncriterion = nn.CrossEntropyLoss()\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n    print(f\"\\n--- Fold {fold+1} ---\")\n\n    train_data = train_df.iloc[train_idx]\n    val_data = train_df.iloc[val_idx]\n\n    train_dataset = SoilDataset(train_data, TRAIN_DIR, transform=train_transform)\n    val_dataset = SoilDataset(val_data, TRAIN_DIR, transform=test_transform)\n\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n    model = efficientnet_b3(weights=EfficientNet_B3_Weights.DEFAULT)\n    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n    model = model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n\n    best_acc = 0\n    best_model_wts = copy.deepcopy(model.state_dict())\n\n    for epoch in range(10):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        train_acc = correct / total\n        print(f\"Epoch {epoch+1}: Train Acc = {train_acc:.4f}\")\n\n        # Validation\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        val_acc = correct / total\n        print(f\"Val Acc = {val_acc:.4f}\")\n        scheduler.step(val_acc)\n\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n\n    model.load_state_dict(best_model_wts)\n    fold_models.append(copy.deepcopy(model))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:48:09.284717Z","iopub.execute_input":"2025-05-25T08:48:09.284993Z","iopub.status.idle":"2025-05-25T09:02:57.644204Z","shell.execute_reply.started":"2025-05-25T08:48:09.284975Z","shell.execute_reply":"2025-05-25T09:02:57.643537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tta_transforms = [\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(p=1.0),  # Horizontal flip\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomRotation(15),  # Rotate Â±15 degrees\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ])\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:03:19.211773Z","iopub.execute_input":"2025-05-25T09:03:19.212605Z","iopub.status.idle":"2025-05-25T09:03:19.217927Z","shell.execute_reply.started":"2025-05-25T09:03:19.212582Z","shell.execute_reply":"2025-05-25T09:03:19.217092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TTASoilDataset(Dataset):\n    def __init__(self, image_ids, image_dir, transforms_list):\n        self.image_ids = image_ids\n        self.image_dir = image_dir\n        self.transforms_list = transforms_list\n\n    def __len__(self):\n        return len(self.image_ids)\n\n    def __getitem__(self, idx):\n        img_id = self.image_ids[idx]\n        img_path = os.path.join(self.image_dir, img_id)\n        image = Image.open(img_path).convert(\"RGB\")\n\n        # Apply each TTA transform and stack the results\n        images = [tf(image) for tf in self.transforms_list]\n        images = torch.stack(images)  # Shape: [num_tta, C, H, W]\n\n        return img_id, images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:03:38.855855Z","iopub.execute_input":"2025-05-25T09:03:38.856131Z","iopub.status.idle":"2025-05-25T09:03:38.861222Z","shell.execute_reply.started":"2025-05-25T09:03:38.856112Z","shell.execute_reply":"2025-05-25T09:03:38.860598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load test image IDs (REQUIRED before preparing test dataset)\ntest_ids_df = pd.read_csv(TEST_IDS_CSV)\nimage_ids = test_ids_df[\"image_id\"].tolist()\n\n# Now prepare test dataset and loader\ntest_dataset = TTASoilDataset(image_ids, TEST_DIR, tta_transforms)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:05:41.270618Z","iopub.execute_input":"2025-05-25T09:05:41.271192Z","iopub.status.idle":"2025-05-25T09:05:41.283746Z","shell.execute_reply.started":"2025-05-25T09:05:41.27117Z","shell.execute_reply":"2025-05-25T09:05:41.283023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_preds = {img_id: [] for img_id in image_ids}\n\nfor fold, model in enumerate(fold_models):\n    model.eval()\n    model.to(device)\n    print(f\"Running TTA predictions for Fold {fold+1} ...\")\n\n    with torch.no_grad():\n        for img_id, images in tqdm(test_loader):\n            # images shape: [batch=1, num_tta, C, H, W]\n            images = images.squeeze(0).to(device)  # shape: [num_tta, C, H, W]\n\n            # Predict for each TTA image and average\n            outputs = model(images)  # [num_tta, num_classes]\n            probs = torch.softmax(outputs, dim=1)\n            mean_prob = probs.mean(dim=0).cpu().numpy()  # average across TTA\n\n            model_preds[img_id[0]].append(mean_prob)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:06:00.954878Z","iopub.execute_input":"2025-05-25T09:06:00.95516Z","iopub.status.idle":"2025-05-25T09:06:48.412097Z","shell.execute_reply.started":"2025-05-25T09:06:00.955132Z","shell.execute_reply":"2025-05-25T09:06:48.411345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_preds = []\nfor img_id in image_ids:\n    # Stack fold predictions and average\n    fold_probs = np.stack(model_preds[img_id], axis=0)\n    avg_probs = np.mean(fold_probs, axis=0)\n    pred_label = label_encoder.classes_[np.argmax(avg_probs)]\n    final_preds.append(pred_label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:07:03.844054Z","iopub.execute_input":"2025-05-25T09:07:03.844291Z","iopub.status.idle":"2025-05-25T09:07:03.857985Z","shell.execute_reply.started":"2025-05-25T09:07:03.844275Z","shell.execute_reply":"2025-05-25T09:07:03.857433Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"image_id\": image_ids,\n    \"soil_type\": final_preds\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file created: submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:07:17.940559Z","iopub.execute_input":"2025-05-25T09:07:17.940837Z","iopub.status.idle":"2025-05-25T09:07:17.9511Z","shell.execute_reply.started":"2025-05-25T09:07:17.940819Z","shell.execute_reply":"2025-05-25T09:07:17.950354Z"}},"outputs":[],"execution_count":null}]}