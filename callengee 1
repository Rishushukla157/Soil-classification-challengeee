{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d381ad27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:12:24.378824Z",
     "iopub.status.busy": "2025-05-25T11:12:24.378556Z",
     "iopub.status.idle": "2025-05-25T11:12:35.892667Z",
     "shell.execute_reply": "2025-05-25T11:12:35.892071Z"
    },
    "papermill": {
     "duration": 11.519622,
     "end_time": "2025-05-25T11:12:35.894126",
     "exception": false,
     "start_time": "2025-05-25T11:12:24.374504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import copy\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = \"/kaggle/input/soil-classification/soil_classification-2025\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "LABELS_CSV = os.path.join(BASE_DIR, \"train_labels.csv\")\n",
    "TEST_IDS_CSV = os.path.join(BASE_DIR, \"test_ids.csv\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29de1c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:12:35.900087Z",
     "iopub.status.busy": "2025-05-25T11:12:35.899452Z",
     "iopub.status.idle": "2025-05-25T11:12:35.931865Z",
     "shell.execute_reply": "2025-05-25T11:12:35.931157Z"
    },
    "papermill": {
     "duration": 0.036287,
     "end_time": "2025-05-25T11:12:35.933110",
     "exception": false,
     "start_time": "2025-05-25T11:12:35.896823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(LABELS_CSV)\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['soil_type'])\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79225479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:12:35.938560Z",
     "iopub.status.busy": "2025-05-25T11:12:35.938163Z",
     "iopub.status.idle": "2025-05-25T11:12:35.944686Z",
     "shell.execute_reply": "2025-05-25T11:12:35.943947Z"
    },
    "papermill": {
     "duration": 0.010347,
     "end_time": "2025-05-25T11:12:35.945774",
     "exception": false,
     "start_time": "2025-05-25T11:12:35.935427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SoilDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.loc[idx, 'image_id']\n",
    "        img_path = os.path.join(self.image_dir, img_id)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d017ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:12:35.950624Z",
     "iopub.status.busy": "2025-05-25T11:12:35.950422Z",
     "iopub.status.idle": "2025-05-25T11:27:56.628737Z",
     "shell.execute_reply": "2025-05-25T11:27:56.627978Z"
    },
    "papermill": {
     "duration": 920.6822,
     "end_time": "2025-05-25T11:27:56.629975",
     "exception": false,
     "start_time": "2025-05-25T11:12:35.947775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n",
      "100%|██████████| 47.2M/47.2M [00:00<00:00, 196MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc = 0.6663\n",
      "Val Acc = 0.8857\n",
      "Epoch 2: Train Acc = 0.8936\n",
      "Val Acc = 0.9061\n",
      "Epoch 3: Train Acc = 0.9212\n",
      "Val Acc = 0.9429\n",
      "Epoch 4: Train Acc = 0.9519\n",
      "Val Acc = 0.9633\n",
      "Epoch 5: Train Acc = 0.9601\n",
      "Val Acc = 0.9592\n",
      "Epoch 6: Train Acc = 0.9713\n",
      "Val Acc = 0.9592\n",
      "Epoch 7: Train Acc = 0.9744\n",
      "Val Acc = 0.9551\n",
      "Epoch 8: Train Acc = 0.9785\n",
      "Val Acc = 0.9510\n",
      "Epoch 9: Train Acc = 0.9795\n",
      "Val Acc = 0.9714\n",
      "Epoch 10: Train Acc = 0.9826\n",
      "Val Acc = 0.9633\n",
      "\n",
      "--- Fold 2 ---\n",
      "Epoch 1: Train Acc = 0.6561\n",
      "Val Acc = 0.8612\n",
      "Epoch 2: Train Acc = 0.8956\n",
      "Val Acc = 0.9143\n",
      "Epoch 3: Train Acc = 0.9304\n",
      "Val Acc = 0.9429\n",
      "Epoch 4: Train Acc = 0.9376\n",
      "Val Acc = 0.9551\n",
      "Epoch 5: Train Acc = 0.9498\n",
      "Val Acc = 0.9510\n",
      "Epoch 6: Train Acc = 0.9713\n",
      "Val Acc = 0.9673\n",
      "Epoch 7: Train Acc = 0.9703\n",
      "Val Acc = 0.9796\n",
      "Epoch 8: Train Acc = 0.9826\n",
      "Val Acc = 0.9755\n",
      "Epoch 9: Train Acc = 0.9816\n",
      "Val Acc = 0.9755\n",
      "Epoch 10: Train Acc = 0.9877\n",
      "Val Acc = 0.9796\n",
      "\n",
      "--- Fold 3 ---\n",
      "Epoch 1: Train Acc = 0.6452\n",
      "Val Acc = 0.8566\n",
      "Epoch 2: Train Acc = 0.8906\n",
      "Val Acc = 0.9221\n",
      "Epoch 3: Train Acc = 0.9315\n",
      "Val Acc = 0.9262\n",
      "Epoch 4: Train Acc = 0.9407\n",
      "Val Acc = 0.9467\n",
      "Epoch 5: Train Acc = 0.9540\n",
      "Val Acc = 0.9549\n",
      "Epoch 6: Train Acc = 0.9693\n",
      "Val Acc = 0.9713\n",
      "Epoch 7: Train Acc = 0.9744\n",
      "Val Acc = 0.9590\n",
      "Epoch 8: Train Acc = 0.9877\n",
      "Val Acc = 0.9549\n",
      "Epoch 9: Train Acc = 0.9836\n",
      "Val Acc = 0.9590\n",
      "Epoch 10: Train Acc = 0.9857\n",
      "Val Acc = 0.9672\n",
      "\n",
      "--- Fold 4 ---\n",
      "Epoch 1: Train Acc = 0.6483\n",
      "Val Acc = 0.8852\n",
      "Epoch 2: Train Acc = 0.8978\n",
      "Val Acc = 0.9344\n",
      "Epoch 3: Train Acc = 0.9335\n",
      "Val Acc = 0.9549\n",
      "Epoch 4: Train Acc = 0.9509\n",
      "Val Acc = 0.9549\n",
      "Epoch 5: Train Acc = 0.9591\n",
      "Val Acc = 0.9631\n",
      "Epoch 6: Train Acc = 0.9622\n",
      "Val Acc = 0.9631\n",
      "Epoch 7: Train Acc = 0.9734\n",
      "Val Acc = 0.9549\n",
      "Epoch 8: Train Acc = 0.9785\n",
      "Val Acc = 0.9631\n",
      "Epoch 9: Train Acc = 0.9867\n",
      "Val Acc = 0.9631\n",
      "Epoch 10: Train Acc = 0.9898\n",
      "Val Acc = 0.9672\n",
      "\n",
      "--- Fold 5 ---\n",
      "Epoch 1: Train Acc = 0.6800\n",
      "Val Acc = 0.9180\n",
      "Epoch 2: Train Acc = 0.8916\n",
      "Val Acc = 0.9631\n",
      "Epoch 3: Train Acc = 0.9254\n",
      "Val Acc = 0.9713\n",
      "Epoch 4: Train Acc = 0.9479\n",
      "Val Acc = 0.9877\n",
      "Epoch 5: Train Acc = 0.9673\n",
      "Val Acc = 0.9836\n",
      "Epoch 6: Train Acc = 0.9693\n",
      "Val Acc = 0.9877\n",
      "Epoch 7: Train Acc = 0.9765\n",
      "Val Acc = 0.9959\n",
      "Epoch 8: Train Acc = 0.9847\n",
      "Val Acc = 0.9959\n",
      "Epoch 9: Train Acc = 0.9908\n",
      "Val Acc = 0.9959\n",
      "Epoch 10: Train Acc = 0.9816\n",
      "Val Acc = 0.9959\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "fold_models = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "    print(f\"\\n--- Fold {fold+1} ---\")\n",
    "\n",
    "    train_data = train_df.iloc[train_idx]\n",
    "    val_data = train_df.iloc[val_idx]\n",
    "\n",
    "    train_dataset = SoilDataset(train_data, TRAIN_DIR, transform=train_transform)\n",
    "    val_dataset = SoilDataset(val_data, TRAIN_DIR, transform=test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = efficientnet_b3(weights=EfficientNet_B3_Weights.DEFAULT)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
    "\n",
    "    best_acc = 0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: Train Acc = {train_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc = {val_acc:.4f}\")\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    fold_models.append(copy.deepcopy(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec40669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:27:56.644190Z",
     "iopub.status.busy": "2025-05-25T11:27:56.643493Z",
     "iopub.status.idle": "2025-05-25T11:27:56.649597Z",
     "shell.execute_reply": "2025-05-25T11:27:56.648883Z"
    },
    "papermill": {
     "duration": 0.014214,
     "end_time": "2025-05-25T11:27:56.650751",
     "exception": false,
     "start_time": "2025-05-25T11:27:56.636537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tta_transforms = [\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=1.0),  # Horizontal flip\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomRotation(15),  # Rotate ±15 degrees\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd76168e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:27:56.665691Z",
     "iopub.status.busy": "2025-05-25T11:27:56.665454Z",
     "iopub.status.idle": "2025-05-25T11:27:56.671242Z",
     "shell.execute_reply": "2025-05-25T11:27:56.670279Z"
    },
    "papermill": {
     "duration": 0.014841,
     "end_time": "2025-05-25T11:27:56.672611",
     "exception": false,
     "start_time": "2025-05-25T11:27:56.657770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TTASoilDataset(Dataset):\n",
    "    def __init__(self, image_ids, image_dir, transforms_list):\n",
    "        self.image_ids = image_ids\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms_list = transforms_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_id)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply each TTA transform and stack the results\n",
    "        images = [tf(image) for tf in self.transforms_list]\n",
    "        images = torch.stack(images)  # Shape: [num_tta, C, H, W]\n",
    "\n",
    "        return img_id, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dedf3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:27:56.688294Z",
     "iopub.status.busy": "2025-05-25T11:27:56.688043Z",
     "iopub.status.idle": "2025-05-25T11:27:56.699973Z",
     "shell.execute_reply": "2025-05-25T11:27:56.699157Z"
    },
    "papermill": {
     "duration": 0.021019,
     "end_time": "2025-05-25T11:27:56.701182",
     "exception": false,
     "start_time": "2025-05-25T11:27:56.680163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load test image IDs (REQUIRED before preparing test dataset)\n",
    "test_ids_df = pd.read_csv(TEST_IDS_CSV)\n",
    "image_ids = test_ids_df[\"image_id\"].tolist()\n",
    "\n",
    "# Now prepare test dataset and loader\n",
    "test_dataset = TTASoilDataset(image_ids, TEST_DIR, tta_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2689d124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:27:56.716156Z",
     "iopub.status.busy": "2025-05-25T11:27:56.715874Z",
     "iopub.status.idle": "2025-05-25T11:28:44.158828Z",
     "shell.execute_reply": "2025-05-25T11:28:44.158123Z"
    },
    "papermill": {
     "duration": 47.451904,
     "end_time": "2025-05-25T11:28:44.160194",
     "exception": false,
     "start_time": "2025-05-25T11:27:56.708290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TTA predictions for Fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:11<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TTA predictions for Fold 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:08<00:00, 37.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TTA predictions for Fold 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:09<00:00, 37.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TTA predictions for Fold 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:09<00:00, 36.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TTA predictions for Fold 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:08<00:00, 38.01it/s]\n"
     ]
    }
   ],
   "source": [
    "model_preds = {img_id: [] for img_id in image_ids}\n",
    "\n",
    "for fold, model in enumerate(fold_models):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    print(f\"Running TTA predictions for Fold {fold+1} ...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_id, images in tqdm(test_loader):\n",
    "            # images shape: [batch=1, num_tta, C, H, W]\n",
    "            images = images.squeeze(0).to(device)  # shape: [num_tta, C, H, W]\n",
    "\n",
    "            # Predict for each TTA image and average\n",
    "            outputs = model(images)  # [num_tta, num_classes]\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            mean_prob = probs.mean(dim=0).cpu().numpy()  # average across TTA\n",
    "\n",
    "            model_preds[img_id[0]].append(mean_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b543cd4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:28:44.204227Z",
     "iopub.status.busy": "2025-05-25T11:28:44.203980Z",
     "iopub.status.idle": "2025-05-25T11:28:44.219088Z",
     "shell.execute_reply": "2025-05-25T11:28:44.218588Z"
    },
    "papermill": {
     "duration": 0.037737,
     "end_time": "2025-05-25T11:28:44.220109",
     "exception": false,
     "start_time": "2025-05-25T11:28:44.182372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for img_id in image_ids:\n",
    "    # Stack fold predictions and average\n",
    "    fold_probs = np.stack(model_preds[img_id], axis=0)\n",
    "    avg_probs = np.mean(fold_probs, axis=0)\n",
    "    pred_label = label_encoder.classes_[np.argmax(avg_probs)]\n",
    "    final_preds.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cfbea90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:28:44.263170Z",
     "iopub.status.busy": "2025-05-25T11:28:44.262539Z",
     "iopub.status.idle": "2025-05-25T11:28:44.272479Z",
     "shell.execute_reply": "2025-05-25T11:28:44.271898Z"
    },
    "papermill": {
     "duration": 0.032503,
     "end_time": "2025-05-25T11:28:44.273469",
     "exception": false,
     "start_time": "2025-05-25T11:28:44.240966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"image_id\": image_ids,\n",
    "    \"soil_type\": final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file created: submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12375409,
     "sourceId": 102672,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 986.694953,
   "end_time": "2025-05-25T11:28:46.778735",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-25T11:12:20.083782",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
